{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import pymongo as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!brew services start mongodb-community@4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!brew services stop mongodb-community@4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize PyMongo to work with MongoDBs\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pm.MongoClient(conn, maxPoolSize=200)\n",
    "\n",
    "# define db \n",
    "DB_NAME = 'jobscomp'\n",
    "db = client[DB_NAME]\n",
    "col_name = 'descriptions'\n",
    "collection = db[col_name]\n",
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "b5GHDD16YDea",
    "outputId": "926933f9-d3cf-46b1-efe7-645a1d1fc0f2"
   },
   "outputs": [],
   "source": [
    "sources = list(\"\\\n",
    "            http://www.careerbuilder.com \\\n",
    "            http://www.indeed.com \\\n",
    "            https://www.linkedin.com \\\n",
    "            http://careers.stackoverflow.com \\\n",
    "            http://www.glassdoor.com \\\n",
    "            https://angel.co \\\n",
    "            http://www.startuphire.com \\\n",
    "            http://www.monster.com \\\n",
    "            \".split())\n",
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.careerbuilder.com/jobs?utf8=âœ“&keywords=' + job_title + '&location=' + zip_code\n",
    "\n",
    "'https://www.careerbuilder.com/jobs?keywords=%E2%80%9Cdata+scientist%E2%80%9D&location=20005&page_number=2'\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"jobs\"\n",
    "\n",
    "    def start_requests(self):\n",
    "        pages = 1\n",
    "        urls = [\n",
    "            'https://www.careerbuilder.com/jobs?keywords=%E2%80%9Cdata+scientist%E2%80%9D&location=20005&page_number=' \n",
    "            + str(page) for page in range(1, pages + 1)\n",
    "        ]\n",
    "        for url in urls:\n",
    "            yield scrapy.Request(url=url, callback=self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        \n",
    "        # extract data in spider\n",
    "        # another way to select all links is\n",
    "        # response.xpath('//div[@id=\"jobs_collection\"]//a[2]/@href').getall()\n",
    "        # but need to add the first part of the url\n",
    "        jobs_links = response.xpath('//div[@id=\"jobs_collection\"]//a[2]/@href').getall()\n",
    "        yield from response.follow_all(jobs_links, self.parse_job)\n",
    "            \n",
    "    def parse_job(self, response):\n",
    "        yield {\n",
    "            'title': response.xpath('//h1/text()').get(),\n",
    "            'company': response.xpath('//*[@id=\"jdp-data\"]/div[1]/div[2]/div/div[1]/div[1]/span/text()').get(),\n",
    "            'description': ' '.join(response.xpath('//*[@id=\"jdp_description\"]/div[1]/div[1]//text()').extract()),\n",
    "            'date_scraped': date.today()\n",
    "        }\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /Users/yegor/Desktop/data_scientist_comparer/scrapy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yegor/Desktop/data_scientist_comparer\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapy 2.1.0 - no active project\r\n",
      "\r\n",
      "Unknown command: crawl\r\n",
      "\r\n",
      "Use \"scrapy\" to see available commands\r\n"
     ]
    }
   ],
   "source": [
    "# run spider in top directory of scrapy project\n",
    "# and save results to `jobs.json` file\n",
    "!scrapy crawl jobs -o jobs.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[a.attrib['href'] for a in response.xpath('//div[@id=\"jobs_collection\"]//a')] "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Data Scientist Jobs Comparer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('springboard': conda)",
   "language": "python",
   "name": "python38364bitspringboardconda8eec40d942e84bf0a5a0c76aa15b276b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
